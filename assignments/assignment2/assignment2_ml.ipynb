{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asssignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from kafka import KafkaProducer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json, lit, rand\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = {\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/hajta2/.local/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/hajta2/.ivy2/cache\n",
      "The jars for the packages stored in: /home/hajta2/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-d6b4fd0f-25f5-405f-beb3-a6508535f7fe;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.4.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.4.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.3.2 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.9.1 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.6 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      ":: resolution report :: resolve 760ms :: artifacts dl 37ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.3.2 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.4.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.4.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.6 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.9.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   11  |   0   |   0   |   0   ||   11  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-d6b4fd0f-25f5-405f-beb3-a6508535f7fe\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 11 already retrieved (0kB/26ms)\n",
      "23/05/26 20:24:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "spark = SparkSession.builder.appName('assignment3').config(\"spark.jars.packages\", \",\".join(packages)).getOrCreate()\n",
    "producer = KafkaProducer(bootstrap_servers='localhost:9092')\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = \"user-top-read playlist-modify-public playlist-modify-private\"\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.send('tracks_topic', b'')\n",
    "producer.send('audio_features_topic', b'')\n",
    "producer.send('trending_tracks_topic', b'')\n",
    "df = (\n",
    "    spark.readStream.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "    .option(\"subscribe\", \"tracks_topic, audio_features_topic, trending_tracks_topic\")\n",
    "    .option(\"startingOffsets\", \"latest\")\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_stream = df.selectExpr(\"CAST(value AS STRING)\").filter(\"topic = 'tracks_topic'\")\n",
    "features_stream = df.selectExpr(\"CAST(value AS STRING)\").filter(\"topic = 'audio_features_topic'\")\n",
    "trending_tracks_stream = df.selectExpr(\"CAST(value AS STRING)\").filter(\"topic = 'trending_tracks_topic'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_query = tracks_stream.writeStream.format(\"memory\").queryName(\"tracks\").start()\n",
    "features_query = features_stream.writeStream.format(\"memory\").queryName(\"features\").start()\n",
    "trending_tracks_query = trending_tracks_stream.writeStream.format(\"memory\").queryName(\"trending_tracks\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "saved_tracks = sp.current_user_top_tracks(limit=50, offset=0, time_range='short_term')\n",
    "for track in saved_tracks['items']:\n",
    "    producer.send('tracks_topic', json.dumps(track).encode('utf-8'))\n",
    "    audio_features = sp.audio_features(track['id'])\n",
    "    producer.send('audio_features_topic', json.dumps(audio_features[0]).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trending_playlist_id = sp.featured_playlists(limit=1, country='HU', locale='hu_HU')['playlists']['items'][0]['id']\n",
    "trending_tracks = sp.playlist_tracks(trending_playlist_id, limit=50, offset=0, market='HU')['items']\n",
    "for item in trending_tracks:\n",
    "    track = item['track']\n",
    "    producer.send('trending_tracks_topic', json.dumps(track).encode('utf-8'))\n",
    "    audio_features = sp.audio_features(track['id'])\n",
    "    producer.send('audio_features_topic', json.dumps(audio_features[0]).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = spark.sql(\"select * from tracks\")\n",
    "features = spark.sql(\"select * from features\")\n",
    "trending_tracks = spark.sql(\"select * from trending_tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracks: 50\n",
      "Features: 100\n",
      "Trending tracks: 50\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tracks: {tracks.count()}\")\n",
    "print(f\"Features: {features.count()}\")\n",
    "print(f\"Trending tracks: {trending_tracks.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_query.stop()\n",
    "features_query.stop()\n",
    "trending_tracks_query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tracks.printSchema()\n",
    "features.printSchema()\n",
    "trending_tracks.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_schema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"artists\", StringType(), True),\n",
    "        StructField(\"duration_ms\", IntegerType(), True),\n",
    "        StructField(\"popularity\", FloatType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tracks_parsed = tracks.withColumn(\n",
    "    \"parsed_value\", from_json(col(\"value\"), tracks_schema)\n",
    ").select(\"parsed_value.*\")\n",
    "trending_tracks_parsed = trending_tracks.withColumn(\n",
    "    \"parsed_value\", from_json(col(\"value\"), tracks_schema)\n",
    ").select(\"parsed_value.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- artists: string (nullable = true)\n",
      " |-- duration_ms: integer (nullable = true)\n",
      " |-- popularity: float (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- artists: string (nullable = true)\n",
      " |-- duration_ms: integer (nullable = true)\n",
      " |-- popularity: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tracks_parsed.printSchema()\n",
    "trending_tracks_parsed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracks: 50\n",
      "Trending tracks: 50\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tracks: {tracks_parsed.count()}\")\n",
    "print(f\"Trending tracks: {trending_tracks_parsed.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----------+----------+\n",
      "|                  id|                name|             artists|duration_ms|popularity|\n",
      "+--------------------+--------------------+--------------------+-----------+----------+\n",
      "|4Z4i631BesV0P6LTv...|Talk to Me You'll...|[{\"external_urls\"...|     417099|      55.0|\n",
      "+--------------------+--------------------+--------------------+-----------+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "Tracks: None\n",
      "+--------------------+--------+--------------------+-----------+----------+\n",
      "|                  id|    name|             artists|duration_ms|popularity|\n",
      "+--------------------+--------+--------------------+-----------+----------+\n",
      "|7n5JBAnjVBTFgTEsd...|Inkasszó|[{\"external_urls\"...|     149673|      38.0|\n",
      "+--------------------+--------+--------------------+-----------+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "Trending tracks: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tracks: {tracks_parsed.show(1)}\")\n",
    "print(f\"Trending tracks: {trending_tracks_parsed.show(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_schema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"danceability\", FloatType(), True),\n",
    "        StructField(\"energy\", FloatType(), True),\n",
    "        StructField(\"key\", IntegerType(), True),\n",
    "        StructField(\"loudness\", FloatType(), True),\n",
    "        StructField(\"mode\", IntegerType(), True),\n",
    "        StructField(\"speechiness\", FloatType(), True),\n",
    "        StructField(\"acousticness\", FloatType(), True),\n",
    "        StructField(\"instrumentalness\", FloatType(), True),\n",
    "        StructField(\"liveness\", FloatType(), True),\n",
    "        StructField(\"valence\", FloatType(), True),\n",
    "        StructField(\"tempo\", FloatType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "features_parsed = features.withColumn(\n",
    "    \"parsed_value\", from_json(col(\"value\"), features_schema)\n",
    ").select(\"parsed_value.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- danceability: float (nullable = true)\n",
      " |-- energy: float (nullable = true)\n",
      " |-- key: integer (nullable = true)\n",
      " |-- loudness: float (nullable = true)\n",
      " |-- mode: integer (nullable = true)\n",
      " |-- speechiness: float (nullable = true)\n",
      " |-- acousticness: float (nullable = true)\n",
      " |-- instrumentalness: float (nullable = true)\n",
      " |-- liveness: float (nullable = true)\n",
      " |-- valence: float (nullable = true)\n",
      " |-- tempo: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_parsed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features: {features_parsed.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+\n",
      "|                  id|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|  tempo|\n",
      "+--------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+\n",
      "|4Z4i631BesV0P6LTv...|       0.741| 0.619|  1| -11.366|   0|     0.0514|       0.661|           0.674|   0.125|  0.146|126.008|\n",
      "+--------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+\n",
      "only showing top 1 row\n",
      "\n",
      "Features: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features: {features_parsed.show(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_tracks = tracks_parsed.join(features_parsed, tracks_parsed.id == features_parsed.id).drop(features_parsed.id)\n",
    "joined_trending_tracks = trending_tracks_parsed.join(features_parsed, trending_tracks_parsed.id == features_parsed.id).drop(features_parsed.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined tracks: 50\n",
      "Joined trending tracks: 50\n"
     ]
    }
   ],
   "source": [
    "print(f\"Joined tracks: {joined_tracks.count()}\")\n",
    "print(f\"Joined trending tracks: {joined_trending_tracks.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_tracks = joined_tracks.withColumn('favorite', lit(1))\n",
    "joined_trending_tracks = joined_trending_tracks.withColumn('favorite', lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tracks = joined_tracks.union(joined_trending_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tracks = combined_tracks.orderBy(rand())\n",
    "train, X_test = combined_tracks.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"duration_ms\", \"popularity\", \"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\"], outputCol=\"features\")\n",
    "assembled_train = assembler.transform(train)\n",
    "assembled_test = assembler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(featuresCol='features', labelCol='favorite', numTrees=100, maxDepth=5, maxBins=32)\n",
    "model = random_forest.fit(assembled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(assembled_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
