{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asssignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from kafka import KafkaProducer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json, lit, rand, udf, to_json, struct\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    FloatType,\n",
    ")\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = {\n",
    "    \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0,com.redislabs:spark-redis_2.12:3.1.0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/hajta2/.local/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/hajta2/.ivy2/cache\n",
      "The jars for the packages stored in: /home/hajta2/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "com.redislabs#spark-redis_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7f2027f4-4738-41bd-b653-7800fdd768d3;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.4.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.4.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.3.2 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.9.1 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.6 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      "\tfound com.redislabs#spark-redis_2.12;3.1.0 in central\n",
      "\tfound redis.clients#jedis;3.9.0 in central\n",
      ":: resolution report :: resolve 583ms :: artifacts dl 17ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcom.redislabs#spark-redis_2.12;3.1.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.3.2 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.4.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.4.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.6 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.9.1 from central in [default]\n",
      "\tredis.clients#jedis;3.9.0 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.slf4j#slf4j-api;1.7.30 by [org.slf4j#slf4j-api;2.0.6] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   14  |   0   |   0   |   1   ||   13  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7f2027f4-4738-41bd-b653-7800fdd768d3\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 13 already retrieved (0kB/13ms)\n",
      "23/05/28 16:45:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"assignment3\")\n",
    "    .config(\"spark.jars.packages\", \",\".join(packages))\n",
    "    .config(\"spark.redis.port\", \"6379\")\n",
    "    .config(\"spark.redis.host\", \"127.0.0.1\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "producer = KafkaProducer(bootstrap_servers=\"localhost:9092\")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = \"user-top-read playlist-modify-public playlist-modify-private\"\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.send(\"liked_tracks_topic\", b\"\")\n",
    "producer.send(\"not_liked_tracks_topic\", b\"\")\n",
    "producer.send(\"trending_tracks_topic\", b\"\")\n",
    "producer.send(\"audio_features_topic\", b\"\")\n",
    "df = (\n",
    "    spark.readStream.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "    .option(\"subscribe\", \"liked_tracks_topic, audio_features_topic, trending_tracks_topic, not_liked_tracks_topic\")\n",
    "    .option(\"startingOffsets\", \"latest\")\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "liked_tracks_stream = df.selectExpr(\"CAST(value AS STRING)\").filter(\"topic = 'liked_tracks_topic'\")\n",
    "not_liked_tracks_stream = df.selectExpr(\"CAST(value AS STRING)\").filter(\"topic = 'not_liked_tracks_topic'\")\n",
    "features_stream = df.selectExpr(\"CAST(value AS STRING)\").filter(\n",
    "    \"topic = 'audio_features_topic'\"\n",
    ")\n",
    "trending_tracks_stream = df.selectExpr(\"CAST(value AS STRING)\").filter(\n",
    "    \"topic = 'trending_tracks_topic'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "liked_tracks_query = liked_tracks_stream.writeStream.format(\"memory\").queryName(\"liked_tracks\").start()\n",
    "not_liked_tracks_query = not_liked_tracks_stream.writeStream.format(\"memory\").queryName(\"not_liked_tracks\").start()\n",
    "features_query = (\n",
    "    features_stream.writeStream.format(\"memory\").queryName(\"features\").start()\n",
    ")\n",
    "trending_tracks_query = (\n",
    "    trending_tracks_stream.writeStream.format(\"memory\")\n",
    "    .queryName(\"trending_tracks\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "saved_tracks = sp.current_user_top_tracks(limit=50, offset=0, time_range=\"short_term\")\n",
    "for track in saved_tracks[\"items\"]:\n",
    "    producer.send(\"liked_tracks_topic\", json.dumps(track).encode(\"utf-8\"))\n",
    "    audio_features = sp.audio_features(track[\"id\"])\n",
    "    producer.send(\"audio_features_topic\", json.dumps(audio_features[0]).encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_id = \"37i9dQZF1DX8SfyqmSFDwe\"\n",
    "not_liked_tracks = sp.playlist_tracks(playlist_id, limit=100, offset=0)\n",
    "for item in not_liked_tracks[\"items\"]:\n",
    "    track = item[\"track\"]\n",
    "    producer.send(\"not_liked_tracks_topic\", json.dumps(track).encode(\"utf-8\"))\n",
    "    audio_features = sp.audio_features(track[\"id\"])\n",
    "    producer.send(\"audio_features_topic\", json.dumps(audio_features[0]).encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_playlist_id = sp.featured_playlists(limit=1, country=\"HU\", locale=\"hu_HU\")[\n",
    "    \"playlists\"\n",
    "][\"items\"][0][\"id\"]\n",
    "trending_tracks = sp.playlist_tracks(\n",
    "    trending_playlist_id, limit=50, offset=0, market=\"HU\"\n",
    ")[\"items\"]\n",
    "for item in trending_tracks:\n",
    "    track = item[\"track\"]\n",
    "    producer.send(\"trending_tracks_topic\", json.dumps(track).encode(\"utf-8\"))\n",
    "    audio_features = sp.audio_features(track[\"id\"])\n",
    "    producer.send(\"audio_features_topic\", json.dumps(audio_features[0]).encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "liked_tracks = spark.sql(\"select * from liked_tracks\")\n",
    "not_liked_tracks = spark.sql(\"select * from not_liked_tracks\")\n",
    "features = spark.sql(\"select * from features\")\n",
    "trending_tracks = spark.sql(\"select * from trending_tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracks: 50\n",
      "Not liked tracks: 100\n",
      "Trending tracks: 50\n",
      "Features: 200\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tracks: {liked_tracks.count()}\")\n",
    "print(f\"Not liked tracks: {not_liked_tracks.count()}\")\n",
    "print(f\"Trending tracks: {trending_tracks.count()}\")\n",
    "print(f\"Features: {features.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "liked_tracks_query.stop()\n",
    "not_liked_tracks_query.stop()\n",
    "features_query.stop()\n",
    "trending_tracks_query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "liked_tracks.printSchema()\n",
    "not_liked_tracks_stream.printSchema()\n",
    "features.printSchema()\n",
    "trending_tracks.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_schema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"artists\", StringType(), True),\n",
    "        StructField(\"duration_ms\", IntegerType(), True),\n",
    "        StructField(\"popularity\", FloatType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "liked_tracks_parsed = liked_tracks.withColumn(\n",
    "    \"parsed_value\", from_json(col(\"value\"), tracks_schema)\n",
    ").select(\"parsed_value.*\")\n",
    "not_liked_tracks_parsed = not_liked_tracks.withColumn(\n",
    "    \"parsed_value\", from_json(col(\"value\"), tracks_schema)\n",
    ").select(\"parsed_value.*\")\n",
    "trending_tracks_parsed = trending_tracks.withColumn(\n",
    "    \"parsed_value\", from_json(col(\"value\"), tracks_schema)\n",
    ").select(\"parsed_value.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- artists: string (nullable = true)\n",
      " |-- duration_ms: integer (nullable = true)\n",
      " |-- popularity: float (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+-----------+----------+\n",
      "|                  id|                name|             artists|duration_ms|popularity|\n",
      "+--------------------+--------------------+--------------------+-----------+----------+\n",
      "|4Z4i631BesV0P6LTv...|Talk to Me You'll...|[{\"external_urls\"...|     417099|      55.0|\n",
      "+--------------------+--------------------+--------------------+-----------+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "Tracks: None\n"
     ]
    }
   ],
   "source": [
    "liked_tracks_parsed.printSchema()\n",
    "print(f\"Tracks: {liked_tracks_parsed.show(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_schema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"danceability\", FloatType(), True),\n",
    "        StructField(\"energy\", FloatType(), True),\n",
    "        StructField(\"key\", IntegerType(), True),\n",
    "        StructField(\"loudness\", FloatType(), True),\n",
    "        StructField(\"mode\", IntegerType(), True),\n",
    "        StructField(\"speechiness\", FloatType(), True),\n",
    "        StructField(\"acousticness\", FloatType(), True),\n",
    "        StructField(\"instrumentalness\", FloatType(), True),\n",
    "        StructField(\"liveness\", FloatType(), True),\n",
    "        StructField(\"valence\", FloatType(), True),\n",
    "        StructField(\"tempo\", FloatType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "features_parsed = features.withColumn(\n",
    "    \"parsed_value\", from_json(col(\"value\"), features_schema)\n",
    ").select(\"parsed_value.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- danceability: float (nullable = true)\n",
      " |-- energy: float (nullable = true)\n",
      " |-- key: integer (nullable = true)\n",
      " |-- loudness: float (nullable = true)\n",
      " |-- mode: integer (nullable = true)\n",
      " |-- speechiness: float (nullable = true)\n",
      " |-- acousticness: float (nullable = true)\n",
      " |-- instrumentalness: float (nullable = true)\n",
      " |-- liveness: float (nullable = true)\n",
      " |-- valence: float (nullable = true)\n",
      " |-- tempo: float (nullable = true)\n",
      "\n",
      "Features: 200\n",
      "+--------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+\n",
      "|                  id|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|  tempo|\n",
      "+--------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+\n",
      "|4Z4i631BesV0P6LTv...|       0.741| 0.619|  1| -11.366|   0|     0.0514|       0.661|           0.674|   0.125|  0.146|126.008|\n",
      "+--------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+\n",
      "only showing top 1 row\n",
      "\n",
      "Features: None\n"
     ]
    }
   ],
   "source": [
    "features_parsed.printSchema()\n",
    "print(f\"Features: {features_parsed.count()}\")\n",
    "print(f\"Features: {features_parsed.show(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_liked_tracks = liked_tracks_parsed.join(\n",
    "    features_parsed, liked_tracks_parsed.id == features_parsed.id\n",
    ").drop(features_parsed.id)\n",
    "joined_not_liked_tracks = not_liked_tracks_parsed.join(\n",
    "    features_parsed, not_liked_tracks_parsed.id == features_parsed.id\n",
    ").drop(features_parsed.id)\n",
    "joined_trending_tracks = trending_tracks_parsed.join(\n",
    "    features_parsed, trending_tracks_parsed.id == features_parsed.id\n",
    ").drop(features_parsed.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_liked_tracks = joined_liked_tracks.withColumn(\"favorite\", lit(1))\n",
    "joined_not_liked_tracks = joined_trending_tracks.withColumn(\"favorite\", lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tracks = joined_liked_tracks.union(joined_not_liked_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tracks = combined_tracks.orderBy(rand())\n",
    "X_train, X_test = combined_tracks.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"duration_ms\",\n",
    "        \"popularity\",\n",
    "        \"danceability\",\n",
    "        \"energy\",\n",
    "        \"key\",\n",
    "        \"loudness\",\n",
    "        \"mode\",\n",
    "        \"speechiness\",\n",
    "        \"acousticness\",\n",
    "        \"instrumentalness\",\n",
    "        \"liveness\",\n",
    "        \"valence\",\n",
    "        \"tempo\",\n",
    "    ],\n",
    "    outputCol=\"features\",\n",
    ")\n",
    "assembled_train = assembler.transform(X_train)\n",
    "assembled_test = assembler.transform(X_test)\n",
    "assembled_trending = assembler.transform(joined_trending_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)\n",
    "scalerModel = scaler.fit(assembled_train)\n",
    "scaled_train = scalerModel.transform(assembled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(\n",
    "    featuresCol=\"features\", labelCol=\"favorite\", numTrees=100, maxDepth=5, maxBins=32\n",
    ")\n",
    "model = random_forest.fit(scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8260869565217391\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(assembled_test)\n",
    "print(f\"Precision: {predictions.filter(predictions.favorite == predictions.prediction).count() / predictions.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ith_(v, i):\n",
    "    try:\n",
    "        return float(v[i])\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "ith = udf(ith_, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = model.transform(assembled_trending).filter(ith(col(\"probability\"), lit(1)) > 0.3).orderBy(col(\"probability\").desc()).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 408:=========================================>             (12 + 4) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----------+----------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------------+--------------------+--------------------+----------+\n",
      "|                  id|                name|             artists|duration_ms|popularity|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|  tempo|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+-----------+----------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------------+--------------------+--------------------+----------+\n",
      "|3C1ejh3RlOsfBOkwA...|        Nehéz vagyok|[{\"external_urls\"...|     180750|      36.0|       0.482| 0.706|  0|  -5.918|   1|     0.0952|       0.144|             0.0|  0.0851|  0.482|203.917|[180750.0,36.0,0....|[65.5135551765905...|[0.65513555176590...|       0.0|\n",
      "|5R3ypZktJsKd1Aqs4...|          Érj hozzám|[{\"external_urls\"...|     198979|      38.0|       0.587| 0.777|  8|  -6.912|   1|      0.124|      0.0476|          1.1E-4|   0.306|  0.338| 97.955|[198979.0,38.0,0....|[62.7315911095448...|[0.62731591109544...|       0.0|\n",
      "|49AG4MU3Ij6a8NWEV...|From Gaza, With Love|[{\"external_urls\"...|     119747|      60.0|       0.829| 0.486|  7|  -9.569|   1|      0.159|         0.6|           0.191|   0.127|  0.255|116.045|[119747.0,60.0,0....|[37.8887809151581...|[0.37888780915158...|       1.0|\n",
      "+--------------------+--------------------+--------------------+-----------+----------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "recommendations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "recommendations_json = recommendations.select('id', 'name', 'artists', 'probability').toJSON().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json = {}\n",
    "for track in recommendations_json:\n",
    "    track = json.loads(track)\n",
    "    artists = [artist[\"name\"] for artist in json.loads(track[\"artists\"])]\n",
    "    output_json[track[\"id\"]] = {\n",
    "        \"name\": track[\"name\"],\n",
    "        \"artists\": artists,\n",
    "        \"probability\": track[\"probability\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(list(output_json.items()), [\"id\", \"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.format('org.apache.spark.sql.redis').option('table', 'recommendations').option('key.column', 'id').save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
